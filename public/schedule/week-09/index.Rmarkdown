---
title: "Week 09: Linear models"
weight: 9
---

<style>
table {
font-size: 18px;
}

</style>

## Lectures

|           | Slides                   | Videos | Application Exercise (AE) |
|-----------|--------------------------|--------|--------|
| Monday    | Statistics experience |  | No AE 17|
| Wednesday |  [Introducing linear models](https://sta199-fa20-002.netlify.app/slides/18-introduce-linear-model.html) | [Introducing linear models](https://warpwire.duke.edu/w/h6EEAA/) | [AE 18: Car prices](https://sta199-fa20-002.netlify.app/appex/appex18-intro-regression.html) |
|  |   | [Interpreting models](https://warpwire.duke.edu/w/YaEEAA/) |  |
|  |   | [Categorical predictors](https://warpwire.duke.edu/w/VaEEAA/) |  |
|  |   | [Prediction + tidy output](https://warpwire.duke.edu/w/R6EEAA/) |  |


## Readings

|            |   |
|------------|---|
|[Introduction to Modern Statistics: 3 Introduction to linear models](https://openintro-ims.netlify.app/intro-linear-models.html)| **Required**   |


## Assignments

|                        |   |
|------------------------|---|
| [Statistics experience](https://sta199-fa20-002.netlify.app/hw/stat-experience.html) | **due Oct 18  at 11:59p** |
| [HW 02](https://sta199-fa20-002.netlify.app/hw/hw-02.html)| **due Oct 19 at 11:59p** |
| [Lab 07](https://sta199-fa20-002.netlify.app/labs/lab-07-burritos.html) | **due Oct 21 at 11:59p** |

## Announcements

### Tea with a TA!

Hang out with the TAs from STA 199! This is a casual conversation and a fun opportunity to meet the members of the STA 199 teaching time. The only rule is these can't turn into office hours! 

Tea with a TA counts as a statistics experience.

**Upcoming Tea with a TA events**

- [**Salvador Arellano**](https://www.linkedin.com/in/salvador-chavero-arellano/), Wed Oct 21, 12p - 1p
  - [Click here](https://forms.gle/CVNc83EsqeuWLj5XA) to sign up
  
- **Morris Greenberg**, Fri Oct 23, 1p - 2p
  - [Click here](https://forms.gle/PgVeB34UhpbvEbqn7) to sign up
  - *Morris Greenberg graduated from Tufts University in 2016 majoring in Mathematics and Quantitative Economics with a Computer Science minor. While at Tufts, he started his love of data science working with baseball data as the leader of the Baseball Analysis at Tufts (BAT) club, and eventually interning and consulting for the Washington Nationals in his final year. Thereafter, he worked at Analysis Group, an economic consulting firm, for 3 years as an analyst/senior analyst, specializing in healthcare projects. He is now a master's student in the Statistical Science department at Duke, and does research with Li Ma and the medical school with microbiome data, trying to model how the human gut changes over time. In his spare time, he enjoys hiking, playing guitar, playing scrabble and crossword puzzles, doing yoga, and cooking Indian food.*

### MLBytes + H2O.ai: Training Understandable, Fair, Trustable and Accurate Predictive Modeling Systems

**THIS Friday 10/16, 4:30-5:30pm (see Sakai for Zoom details)**: Duke Undergraduate Machine Learning is hosting its second MLBytes talk of the semester this Friday, October 16th with Navdeep Gill of H2O.ai. MLBytes are 45-minute talks by machine learning researchers and industry professionals, with opportunities for questions afterwards. Whether you are new to machine learning or are a seasoned veteran, MLBytes give you a first-hand opportunity to learn from experts about an interesting fields of research, real-world applications of machine learning, and more! Come to MLBytes this Friday, Oct 16 from 4:30-5:30pm on Zoom  Reach out to [hello@dukeml.org](mailto:hello@dukeml.org) if you have any questions!   

**Talk Abstract:**

This presentation illustrates how to combine innovations from several sub-disciplines of machine learning research to train understandable, fair, trustable, and accurate predictive modeling systems. Techniques from research into fair models, directly interpretable Bayesian or constrained machine learning models, and post-hoc explanations can be used to train transparent, fair, and accurate models and make nearly every aspect of their behavior understandable and accountable to human users. Additional techniques from fairness research can be used to check for sociological bias in model predictions and to preprocess data and post-process predictions to ensure the fairness of predictive models, which are very important for applications of machine learning to humans. Furthermore, security and privacy in machine learning, along with fairness, come together to build a human-centered focus of machine learning. Finally, several practices applying new testing and debugging techniques, often inspired by best practices in software engineering, can increase the trustworthiness of model predictions on unseen data. Together these techniques create a the emerging field of  “Responsible AI”, which is suitable for use in business- and life-critical decision support.

**Speaker Bio:**

Navdeep Gill is a Senior Data Scientist and Software Engineer at H2O.ai where he focuses mainly on responsible machine learning. Navdeep has also contributed to H2O.ai’s efforts in GPU accelerated machine learning, automated machine learning, and to the core H2O-3 machine learning platform.

### This is Statistics Fall Data Challenge

[Click here](https://thisisstatistics.org/falldatachallenge/) for details on the Get out the Vote! Fall Data Challenge by the American Statistical Association (ASA). Submissions are due **November 11**.




