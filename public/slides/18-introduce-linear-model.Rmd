---
title: "Introducing linear models"
author: "Prof. Maria Tackett"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta199-slides.css"
    logo: img/sta199-sticker-icon.png
    lib_dir: libs/font-awesome
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%" 
      ratio: "16:9"
---


layout: true

<div class="my-footer">
<span>
<a href="http://datasciencebox.org" target="_blank">datasciencebox.org</a>
</span>
</div> 


```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
knitr::opts_chunk$set(fig.height = 3, fig.width = 5, dpi = 300, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.align = "center") 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
# For magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}
# For ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(DT)
library(emo)
library(openintro)
library(infer)
library(patchwork)
library(kableExtra)
```

---

class: middle center

## [Click for PDF of slides](18-introduce-linear-model.pdf)
---


class: middle, center

## The language of models

---

## Modeling

- We use models to...
  - understand relationships
  - assess differences
  - make predictions


- We will focus on .vocab[linear] models but there are many other types.

---

class: center, middle

# Data: Paris Paintings

---

## Paris Paintings

```{r message=FALSE}
paris_paintings <- read_csv("data/paris_paintings.csv", 
                            na = c("n/a", "", "NA"))
```


[Click here](https://sta199-fa20-002.netlify.app/slides/paris_codebook.html) for Paris Paintings codebook

.pull-left[
```{r echo = F, out.width = "30%", fig.cap = "Sandra van Ginhoven"}
knitr::include_graphics("img/18/sandra-van-ginhoven.png")
```
]

.pull-right[
```{r echo = F, out.width = "30%", fig.cap = "Hilary Coe Cronheim"}
knitr::include_graphics("img/18/hilary-coe-cronheim.png")
```
]

PhD students in the Duke Art, Law, and Markets Initiative in 2013

.footnote[**Source**: Printed catalogs of 28 auction sales in Paris, 1764- 1780 - 3,393 paintings, their prices, and descriptive details from sales catalogs over 60 variables]

---

## Auctions today

```{r echo = F, out.width = "70%"}
knitr::include_graphics("img/18/auction-video.png")
```

[https://www.youtube.com/watch?v=apaE1Q7r4so](https://www.youtube.com/watch?v=apaE1Q7r4so)

---

## Auctions back in the day

```{r echo = F, out.width = "70%"}
knitr::include_graphics("img/18/old-auction.png")
```

de Machy, Public Sale at the Hôtel Bullion, Musée Carnavalet, Paris (18th century)
---

## Paris auction market

```{r echo = F, out.width = "70%"}
knitr::include_graphics("img/18/auction-trend-paris.png")
```

---

## Depart pour la chasse

```{r echo = F, out.width = "60%"}
knitr::include_graphics("img/18/depart-pour-la-chasse.png")
```

---

## Auction catalogue text

.pull-left[
```{r echo = F, out.width = "70%"}
knitr::include_graphics("img/18/auction-catalogue.png")
```
]

.pull-right[
.small[Two paintings very rich in composition, of a beautiful execution, and whose merit is very remarkable, each 17 inches 3 lines high, 23 inches wide; the first, painted on wood, comes from the Cabinet of Madame la Comtesse de Verrue; it represents a departure for the hunt: it shows in the front a child on a white horse, a man who gives the horn to gather the dogs, a falconer and other figures nicely distributed across the width of the painting; two horses drinking from a fountain; on the right in the corner a lovely country house topped by a terrace, on which people are at the table, others who play instruments; trees and fabriques pleasantly enrich the background.]
]

---

```{r}
paris_paintings %>% filter(name == "R1777-89a") %>% 
  select(name:endbuyer) %>% glimpse()
```

---

```{r}
paris_paintings %>% filter(name == "R1777-89a") %>% 
  select(Interm:finished) %>% glimpse()
```

---

```{r}
paris_paintings %>% filter(name == "R1777-89a") %>% 
  select(lrgfont:other) %>% glimpse()
```

---

class: center, middle

## Modeling the relationship between variables

---

## Describe the distribution of price

.midi[
```{r, fig.height = 2}
ggplot(data = paris_paintings, aes(x = price)) +
  geom_histogram(binwidth = 1000) +
  labs(title="Distribution of Price (in Livres)")
```
]
---

## Height

```{r, fig.height = 2}
ggplot(data = paris_paintings, aes(x = Height_in)) +
  geom_histogram()
```

---

## Width

```{r, fig.height = 2}
ggplot(data = paris_paintings, aes(x = Width_in)) +
  geom_histogram()
```

---

## Models as functions

- We can represent relationships between variables using **functions**

- A .vocab[function] in the *mathematical* sense is the relationship between one or more inputs and an output created from those inputs. 
    - Plug in the inputs and receive back the output
    
--

- The formula $y = 3x + 7$ is a function with input $x$ and output $y$.
  - When $x$ is $5$, the output $y$ is $22$
    
    ```
    y = 3 * 5 + 7 = 22
    ```
    
--

  - When $x$ is $12$, the output of $y$ is $43$
  
    ```
    y = 3 * 12 + 7 = 43
    ```

---

## Visualizing the linear model

.midi[
```{r warning = FALSE, fig.height = 2}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm") 
```
]

---


## Visualizing the linear model

.midi[
```{r warning = FALSE, fig.height = 2}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm") #<<
```
]

---

## Visualizing the linear model

.midi[
```{r warning = FALSE, fig.height = 2}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, 
              col = "red", lty = 2, lwd = 3) #<<
```
]

---

## Vocabulary

- .vocab[Response variable]: Variable whose behavior or variation you are trying to understand, on the y-axis. Also called the **dependent variable**.

--

- .vocab[Explanatory variables]: Other variables that you want to use to explain the variation in the response, on the x-axis. Also called **independent variables**, **predictors**, or **features**.

--

- .vocab[Predicted value]:</font> Output of the **model function**
    - The model function gives the typical value of the response variable
    *conditioning* on the explanatory variables (what does this mean?)

---

## Vocabulary

- .vocab[Residuals]: Shows how far each case is from its predicted value
   - **Residual = Observed value - Predicted value**
   - Tells how far above/below the model function each case is

---

.question[
What does a negative residual mean? Which paintings on the plot have have negative 
residuals, those below or above the line?
]

```{r warning = FALSE, echo=FALSE, fig.height = 2}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

---

## Residuals

```{r warning = FALSE, fig.height=2.25, fig.width=5 ,echo = FALSE}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, 
              col = "blue", lty = 1, lwd = 1) + 
  geom_point(aes(x = 141, y = 27), col = "red", shape = 1, size = 4)
```

---

## Residuals


```{r warning = FALSE, fig.height=2.25, fig.width=5 ,echo = FALSE}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, 
              col = "blue", lty = 1, lwd = 1) + 
  geom_point(aes(x = 141, y = 27), col = "red", shape = 1, size = 4) + 
  geom_segment(aes(x = 141, y = 27, xend = 141, yend = 113.7136), col = "red") + 
    geom_point(aes(x = 141, y = 113.7136), col = "red", shape = 1, size = 4) + 
  annotate("text", x  = 163, y = 75, label = "27 - 113.71 = -86.71", color = "red", size = 2)

```

---

## Residuals


   
```{r warning = FALSE, fig.height=2.25, fig.width=5 ,echo = FALSE}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, 
              col = "blue", lty = 1, lwd = 1) + 
  geom_point(aes(x = 87, y = 120), col = "blue", shape = 1, size = 4)
```

---

## Residuals


```{r warning = FALSE, fig.height=2.25, fig.width=5 ,echo = FALSE}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, 
              col = "blue", lty = 1, lwd = 1) + 
  geom_point(aes(x = 87, y = 120), col = "blue", shape = 1, size = 4) + 
  geom_segment(aes(x = 87, y = 120, xend = 87, yend = 71.551), col = "blue") + 
    geom_point(aes(x = 87, y = 71.551), col = "blue", shape = 1, size = 4) + 
  annotate("text", x  = 100, y = 133, label = "120 -  71.55 = 48.45", color = "blue", size = 2)

```

---

.question[
The plot below displays the relationship between height and width of paintings, but with a lower alpha level. What feature is apparent in this plot that was not (as) apparent in the previous plots? What might be the reason for this feature?
]

```{r warning = FALSE, echo=FALSE, fig.height = 1.75}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point(alpha = 0.2)
```

---

## Landscape paintings

- .vocab[Landscape painting] is the depiction in art of landscapes – natural scenery such as mountains, valleys, trees, rivers, and forests, especially where the main subject is a wide view – with its elements arranged into a coherent composition.<sup>1</sup>
    - Landscape paintings tend to be wider than longer.

- .vocab[Portrait painting] is a genre in painting, where the intent is to depict a human subject.<sup>2</sup>
    - Portrait paintings tend to be longer than wider.

.footnote[[1] Source: Wikipedia, [Landscape painting](https://en.wikipedia.org/wiki/Landscape_painting)
[2] Source: Wikipedia, [Portait painting](https://en.wikipedia.org/wiki/Portrait_painting)]

---

.question[
How, if at all, does the relationship between width and height of paintings vary by whether
or not they have any landscape elements?
]

```{r warning = FALSE, echo = F, fig.height=2}
ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in, 
                      color = factor(landsALL))) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(color = "landscape")
```

---

## Models - upsides and downsides

- Models can sometimes reveal patterns that are not evident in a graph of the
data. This is a great advantage of modeling over simple visual inspection of
data. 

- There is a real risk, however, that a model is imposing structure that is
not really there on the scatter of data, just as people imagine animal shapes in
the stars. A skeptical approach is always warranted.

---

## Variation around the model...

is just as important as the model, if not more!

.question[
*Statistics is the explanation of variation in the context of what remains
unexplained.*
]

- The scatter suggests that there might be other factors that account for large parts 
of painting-to-painting variability, or perhaps just that randomness plays a big role.

- Adding more explanatory variables to a model can sometimes usefully reduce
the size of the scatter around the model. (We'll talk more about this later.)

---

## How do we use models?

1. .vocab[Explanation:] Characterize the relationship between $y$ and $x$ via *slopes* for
numerical explanatory variables or *differences* for categorical explanatory
variables

2. .vocab[Prediction:] Plug in $x$, get the predicted $y$

---

class: middle, center

## Interpreting Models

---


## Packages

.pull-left[
![](img/18/tidyverse.png)

![](img/18/broom.png)
]
.pull-right[
- You're familiar with the tidyverse:
```{r message=FALSE}
library(tidyverse)
```

- The broom package takes the messy output of built-in functions in R, such as `lm`, and turns them into tidy data frames.
```{r message=FALSE}
library(broom)
```
]

---

## broom 

.pull-left[
.middle[
![](img/18/broom.png)
]
]

.pull-right[
- **broom** follows tidyverse principles and tidies up regression output
- **`tidy`**: Constructs a tidy data frame summarizing model's statistical findings
- **`glance`**: Constructs a concise one-row summary of the model
- **`augment`**: Adds columns (e.g. predictions, residuals) to the original data that was modeled
]

[https://broom.tidyverse.org/](https://broom.tidyverse.org/)

---

## Height & width

.midi[
```{r}
m_ht_wt <- lm(Height_in ~ Width_in, data = paris_paintings)
tidy(m_ht_wt)
```
]

--

$$\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}$$

--

- .vocab[Slope]: For each additional inch the painting is wider, the height is expected
to be higher, on average, by 0.78 inches.

--

- .vocab[Intercept]: Paintings that are 0 inches wide are expected to be 3.62 inches high,
on average.
    - Does this make sense?
    
---

## The linear model with a single predictor

- We're interested in the $\beta_0$ (population parameter for the intercept)
and the $\beta_1$ (population parameter for the slope) in the 
following model:

$$ \hat{y} = \beta_0 + \beta_1~x $$

--

- Unfortunately, we can't get these values

--

- So we use sample statistics to estimate them:

$$ \hat{y} = b_0 + b_1~x $$

---

## Least squares regression

The regression line minimizes the sum of squared residuals.

--

- .vocab[Residuals]: </font> $e_i = y_i - \hat{y}_i$,


- The regression line minimizes $\sum_{i = 1}^n e_i^2$.

- Equivalently, minimizing $\sum_{i = 1}^n [y_i - (b_0 + b_1~x_i)]^2$

.question[
Why do we minimize the *squares* of the residuals?
]

---

## Visualizing residuals

```{r echo=FALSE, fig.height = 2.5}
d <- tibble(
    Width_in     = m_ht_wt$model$Width_in,
    Height_in    = m_ht_wt$model$Height_in,
    pred         = m_ht_wt$fitted.values,
    res          = m_ht_wt$residuals
  )
p <- ggplot(data = d, mapping = aes(x = Width_in, y = Height_in)) +
  geom_point(alpha = 0.2) + 
  theme_bw() +
  labs(title = "Height vs. width of paintings", subtitle = "Just the data") +
  xlim(0, 250) +
  ylim(0, 200)
p
```

---

## Visualizing residuals (cont.)

```{r echo=FALSE, fig.height= 2.5}
p <- p + 
  geom_smooth(method = "lm", se = FALSE) +
  geom_point(mapping = aes(y = pred)) +
  labs(subtitle = "Data + least squares regression line")
p
```

---

## Visualizing residuals (cont.)

```{r echo = FALSE, fig.height= 2.5}
p + 
  geom_segment(mapping = aes(xend = Width_in, yend = pred), alpha = 0.4, color="red") +
  labs(subtitle = "Data + least squares regression line + residuals")
```

Check out the applet [here](http://www.rossmanchance.com/applets/RegShuffle.htm) to see this process in action.

---

## Properties of the least squares regression line

- The estimate for the slope, $b_1$, has the same sign as the correlation between the two variables.

- The regression line goes through the center of mass point, the coordinates corresponding to average $x$ and average $y$: $(\bar{x}, \bar{y})$

- The sum of the residuals is zero: 

$$\sum_{i = 1}^n e_i = 0$$

- The residuals and $x$ values are uncorrelated.

---

class: middle, center

## Categorical Predictors

---

## What about non-continuous predictors?

Height & landscape features

```{r}
m_ht_lands <- lm(Height_in ~ factor(landsALL), data = paris_paintings)
tidy(m_ht_lands)
```

--

<br>

$$\widehat{Height_{in}} = 22.68 - 5.65~landsALL$$

---

## (cont.)

$$\widehat{Height_{in}} = 22.68 - 5.65~landsALL$$

- .vocab[Slope:] Paintings with landscape features are expected, on average,
to be 5.65 inches shorter than paintings that without landscape features.
    - Compares baseline level (`landsALL = 0`) to other level
    (`landsALL = 1`).

- .vocab[Intercept:] Paintings that don't have landscape features are expected, on 
average, to be 22.68 inches tall.

---

## Categorical predictor with 2 levels

```{r echo=FALSE}
paris_paintings %>% 
  select(name, price, landsALL) %>% 
  slice(1:8)
```

---

### Categorical predictors with more than 2 levels

.midi[
```{r}
m_ht_sch <- lm(Height_in ~ school_pntg, data = paris_paintings)
tidy(m_ht_sch)
```
]

.question[
What do these rows correspond to? Why are there only six schools listed, but seven schools total (what happened to the Austrian school?)
]

---

### Categorical predictors with more than 2 levels

.midi[
```{r echo = F}
m_ht_sch <- lm(Height_in ~ school_pntg, data = paris_paintings)
tidy(m_ht_sch)
```
]

- When the categorical explanatory variable has many levels, the levels are encoded 
to .vocab[dummy variables]

- Each coefficient describes the expected difference between heights in that particular school compared to the baseline level.


---

## How dummy variables are made

```{r echo=FALSE}
paris_paintings %>% 
  select(school_pntg) %>% 
  group_by(school_pntg) %>% 
  sample_n(1) %>%
  mutate(
    D_FL = as.integer(ifelse(school_pntg == "D/FL", 1L, 0)),
    F    = as.integer(ifelse(school_pntg == "F", 1L, 0)),
    G    = as.integer(ifelse(school_pntg == "G", 1L, 0)),
    I    = as.integer(ifelse(school_pntg == "I", 1L, 0)),
    S    = as.integer(ifelse(school_pntg == "S", 1L, 0)),
    X    = as.integer(ifelse(school_pntg == "X", 1L, 0))
  )
```

---

class: middle, center

## Correlation does not imply causation!!

Remember this when interpreting model coefficients

---

class: center, middle

# Prediction with models

---

## Predict height from width

.question[
On average, how tall are paintings that are 60 inches wide?
$$\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}$$
]

--

```{r}
3.62 + 0.78 * 60
```

"On average, we expect paintings that are 60 inches wide to be 50.42 inches high."

**Warning:** We "expect" this to happen, but there will be some variability.

---

## Prediction vs. extrapolation

.question[
On average, how tall are paintings that are 400 inches wide?
]

```{r extrapolate, warning = FALSE, echo=FALSE, fig.height = 2}
newdata <- tibble(Width_in = 400)
newdata <- newdata %>%
  mutate(Height_in = predict(m_ht_wt, newdata = newdata))

ggplot(data = paris_paintings, aes(x = Width_in, y = Height_in)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", fullrange = TRUE, se = FALSE) +
  xlim(0, 420) +
  ylim(0, 320) +
  geom_segment(data = newdata, mapping = aes(x = Width_in, y = 0, xend = Width_in, yend = Height_in), color = "red", lty = 2) +
  geom_segment(data = newdata, mapping = aes(x = Width_in, y = Height_in, xend = 0, yend = Height_in), color = "red", lty = 2)
```

---

## Watch out for extrapolation!

> "When those blizzards hit the East Coast this winter, it proved to my satisfaction 
that global warming was a fraud. That snow was freezing cold. But in an alarming 
trend, temperatures this spring have risen. Consider this: On February 6th it was 10 
degrees. Today it hit almost 80. At this rate, by August it will be 220 degrees. So 
clearly folks the climate debate rages on."<sup>1</sup>  <br>
Stephen Colbert, April 6th, 2010

.footnote[[1] OpenIntro Statistics. "Extrapolation is treacherous." OpenIntro Statistics.]

---

## Tidy vs. not-so-tidy regression output

Let's revisit the model predicting heights of paintings from their widths:

```{r}
m_ht_wt <- lm(Height_in ~ Width_in, data = paris_paintings)
```

---

## `r emo::ji("x")` Not-so-tidy regression output

- You might come across these in your googling adventures, but we'll try to stay away from them

- Not because they are wrong, but because they don't result in tidy data frames as results.

---

## `r emo::ji("x")` Not-so-tidy regression output (1)

**Option 1:**

```{r}
m_ht_wt
```

---

## `r emo::ji("x")` Not-so-tidy regression output (2)

**Option 2:**

```{r}
summary(m_ht_wt)
```

---

## Review

.question[
What makes a data frame tidy?
]

--

1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.

---

## `r emo::ji("white_check_mark")` Tidy regression output

Achieved with functions from the broom package:

- .vocab[`tidy`]: Constructs a data frame that summarizes the model's statistical findings. We've talked about coefficient estimates and standard errors, but it also displays *test statistics and p-values* (more on these in a few weeks!).

- .vocab[`augment`]: Adds columns to the original data that was modeled. This includes predictions and residuals.

- .vocab[`glance`]: Constructs a concise one-row summary of the model, computed once for the entire model. 

---

## `r emo::ji("white_check_mark")` Tidy your model's statistical findings

```{r}
tidy(m_ht_wt)
```

---

## `r emo::ji("white_check_mark")` Tidy your model's statistical findings


```{r}
tidy(m_ht_wt) %>%
  select(term, estimate) %>%
  mutate(estimate = round(estimate, 3))
```

